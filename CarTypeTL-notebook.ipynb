{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CarTypeTL.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ITuE3C5yJmwoZ2VezhqiTxylbhmPOKp0","authorship_tag":"ABX9TyMiq0tvBWwhegmzm82KOW3d"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"HI0Tw0xkGrFC"},"source":["#data\r\n","!wget http://jana-ubytovani.cz/cars2min.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AgdXKeIOHciK"},"source":["import zipfile\r\n","with zipfile.ZipFile(\"cars2min.zip\", 'r') as zip_ref:\r\n","  zip_ref.extractall(\"data\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-2b26yneaddr"},"source":["! pip install -q pytorch-lightning\r\n","! pip install -q pytorch-lightning-bolts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QG8hTd2aiBh"},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.nn import functional as F\r\n","from torch.utils.data import DataLoader, random_split\r\n","import pytorch_lightning as pl\r\n","import numpy as np\r\n","import torchvision\r\n","from torchvision import datasets, models, transforms\r\n","import matplotlib.pyplot as plt\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","! pip install -q pretrainedmodels\r\n","import pretrainedmodels\r\n","# used CNN architecture\r\n","model_name = 'inceptionresnetv2'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5z5wIf_9WK6O"},"source":["mean = np.array([0.485, 0.456, 0.406])\r\n","std = np.array([0.229, 0.224, 0.225])\r\n","#Test if imgs are loaded, and how they look\r\n","def imgshow(inp,mean=None,std=None,title=None):\r\n","  inp = inp.numpy().transpose((1, 2, 0))\r\n","\r\n","  inp = std * inp + mean\r\n","  inp = np.clip(inp, 0, 1)\r\n","\r\n","  plt.imshow(inp)\r\n","  if title is not None:\r\n","    plt.title(title)\r\n","  plt.pause(0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NuRjcPCUIPoM"},"source":["#data transformations for learning and testing\r\n","data_transforms = {\r\n","    'train': transforms.Compose([\r\n","        transforms.RandomResizedCrop(299),\r\n","        transforms.RandomHorizontalFlip(),\r\n","        transforms.RandomVerticalFlip(),\r\n","        transforms.ToTensor(),\r\n","        transforms.Normalize(mean, std)\r\n","    ]),\r\n","    'val': transforms.Compose([\r\n","        transforms.Resize(256),\r\n","        transforms.CenterCrop(299),\r\n","        transforms.ToTensor(),\r\n","        transforms.Normalize(mean, std)\r\n","    ]),\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0ms21K8IkZR"},"source":["#Show classes and len\r\n","dataset = datasets.ImageFolder(\"data/cars\")\r\n","print(dataset.classes)\r\n","print(len(dataset))\r\n","type(dataset)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQhmd-UOVYLu"},"source":["#Split data to train and validation\r\n","train, val = random_split(dataset, [3431, 858])\r\n","\r\n","train.dataset.transform = data_transforms['train']\r\n","val.dataset.transform = data_transforms['val']\r\n","#batchSize for learning\r\n","batchSize = 8\r\n","\r\n","dataset.classes[0]\r\n","class_counts = torch.tensor([1280,1201, 504, 446])\r\n","numDataPoints = class_counts.sum()\r\n","\r\n","target = torch.cat((torch.zeros(class_counts[0], dtype=torch.long),\r\n","                    torch.ones(class_counts[1], dtype=torch.long),\r\n","                    torch.ones(class_counts[2], dtype=torch.long)*2,\r\n","                    torch.ones(class_counts[3], dtype=torch.long)*3))\r\n","\r\n","print('target train 0/1/2/3: {}/{}/{}/{}'.format(\r\n","    (target == 0).sum(), (target == 1).sum(), (target == 2).sum(),(target == 3).sum()))\r\n","\r\n","# Compute samples weight (each sample should get its own weight)\r\n","class_sample_count = torch.tensor(\r\n","    [(target == t).sum() for t in torch.unique(target, sorted=True)])\r\n","weight = 1. / class_sample_count.float()\r\n","samples_weight = torch.tensor([weight[t] for t in target])\r\n","print(samples_weight)\r\n","# Create sampler, dataset, loader\r\n","sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\r\n","\r\n","print(val)\r\n","\r\n","#create dataloaders\r\n","train_dataloader = DataLoader(train, batch_size=batchSize, num_workers=4, sampler = sampler)\r\n","val_dataloader = DataLoader(val, batch_size=batchSize, num_workers=4)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldCwekd4LrrR"},"source":["class_names = dataset.classes\r\n","inputs, classes = next(iter(train_dataloader))\r\n","out = torchvision.utils.make_grid(inputs)\r\n","imgshow(out,mean,std, title=[class_names[x] for x in classes])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjcxgLWdMfua"},"source":["# class for transfer learning\r\n","class CarTypeRecognizer(pl.LightningModule):\r\n","\r\n","    def __init__(self, num_target_classes):\r\n","        super().__init__()\r\n","        self.model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\r\n","        num_ftrs = self.model.last_linear.in_features\r\n","\r\n","        # self.model = torchvision.models.resnet50(pretrained=True)\r\n","        # num_ftrs = self.model.fc.in_features\r\n","        self.model.fc = nn.Linear(num_ftrs, num_target_classes)\r\n","        self.acc = pl.metrics.Accuracy()\r\n","\r\n","    def forward(self, x):\r\n","        return self.model(x)\r\n","\r\n","    def training_step(self, batch, batch_idx):\r\n","        # --------------------------\r\n","        x, y = batch\r\n","\r\n","        y_hat = self(x)\r\n","        \r\n","        loss = F.cross_entropy(y_hat, y)\r\n","        self.log('train_loss', loss)\r\n","        return loss\r\n","        # --------------------------\r\n","\r\n","    def training_epoch_end(self, outs):\r\n","        acc = self.acc.compute()\r\n","  \r\n","    def validation_step(self, batch, batch_idx):\r\n","        # --------------------------\r\n","        x, y = batch\r\n","        y_hat = self(x)\r\n","        loss = F.cross_entropy(y_hat, y)\r\n","        self.log('val_loss', loss)\r\n","        self.log('test_acc_step', self.acc(y_hat, y), on_step=True, on_epoch=False)\r\n","        # --------------------------\r\n","    def validation_epoch_end(self,outs):\r\n","        acc = self.acc.compute()\r\n","        self.log(\"test_acc_epoch\", acc)   \r\n","    def configure_optimizers(self):\r\n","        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4,weight_decay=1e-5)\r\n","        return optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYcduzo0IGFQ"},"source":["#Model training\r\n","model = CarTypeRecognizer(len(class_names))\r\n","trainer = pl.Trainer(gpus=1, max_epochs=25,progress_bar_refresh_rate=20)\r\n","trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETig_s4LJtLx"},"source":["trainer.save_checkpoint('/content/data/modevSamplerMinb8_25f.ckpt');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rT9zHnkwdxmM"},"source":["torch.save(model.state_dict(), '/content/data/modevSamplerMinb8_25f.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WER0G5TLUV8"},"source":["%load_ext tensorboard\r\n","%tensorboard --logdir lightning_logs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w767Jxp9Lu2d"},"source":["#Test data with visualize / from SMAP Cvičení 29.10. - transfer learning\r\n","import random\r\n","device = torch.device(\"cuda\")\r\n","def vizualize_model(model, num_images=6):\r\n","  model.eval()\r\n","  images_so_far = 0\r\n","  fig = plt.figure()\r\n","\r\n","  for i, (inputs, labels) in enumerate(val_dataloader):\r\n","    if bool(random.getrandbits(1)):\r\n","      continue\r\n","\r\n","    inputs = inputs.to(device)\r\n","    labels = labels.to(device)\r\n","\r\n","    outputs = model(inputs)\r\n","    _, preds = torch.max(outputs, 1)\r\n","\r\n","    for j in range(inputs.size()[0]):\r\n","      images_so_far = images_so_far+1\r\n","      ax = plt.subplot(num_images//2, 2, images_so_far)\r\n","      ax.axis(\"off\")\r\n","      ax.set_title(\"Prediccted: {}, label: {}\".format(class_names[preds[j]], class_names[labels[j]]))\r\n","\r\n","      imgshow(inputs.cpu().data[j],mean,std)\r\n","\r\n","      if images_so_far == num_images:\r\n","        return\r\n","\r\n","\r\n","model.to(device)\r\n","vizualize_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehs7ow-rRT8N"},"source":["# Test function ------------------------------------------------------------------------------------------------------\r\n","newModel=CarTypeRecognizer.load_from_checkpoint('/content/drive/MyDrive/modevSampler.ckpt',num_target_classes=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfmZ7Dq-qXJS"},"source":["loader = transforms.Compose([\r\n","        transforms.RandomResizedCrop(299),\r\n","        transforms.RandomHorizontalFlip(),\r\n","        transforms.RandomVerticalFlip(),\r\n","        transforms.ToTensor(),\r\n","        transforms.Normalize(mean, std)\r\n","    ])\r\n","from PIL import Image\r\n","from torch.autograd import Variable\r\n","def image_loader(image_name):\r\n","    \"\"\"load image, returns cuda tensor\"\"\"\r\n","    image = Image.open(image_name)\r\n","    image = loader(image).float()\r\n","    image = Variable(image, requires_grad=True)\r\n","    image = image.unsqueeze(0)\r\n","    return image.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXJrtDPlqCll"},"source":["imgpath=\"/content/drive/MyDrive/Colab Notebooks/dataset/img/van.jpg\"\r\n","myImg= image_loader(imgpath)\r\n","newModel.eval()\r\n","device = torch.device(\"cuda\")\r\n","newModel.to(device)\r\n","outputs = newModel(myImg)\r\n","_, preds = torch.max(outputs, 1)\r\n","preds"],"execution_count":null,"outputs":[]}]}